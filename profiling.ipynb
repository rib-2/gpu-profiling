{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48fde265-fe4b-4427-896f-df05cdfbd0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a3f90ef-74a2-4aa4-848d-f4a62f3d86e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mprofiling\u001b[0m/  \u001b[01;34mproto\u001b[0m/  \u001b[01;34mserver\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d8796d2-017b-438d-a2e6-00c0f3a1b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, tqdm\n",
    "from server.text_generation_server.models import get_model\n",
    "from text_generation_server.pb.generate_pb2 import Batch, Request, NextTokenChooserParameters, StoppingCriteriaParameters\n",
    "\n",
    "num_tokens = 100\n",
    "iterations = 3\n",
    "model_id = \"bigscience/bloom-560m\"\n",
    "\n",
    "def create_batch(max_tokens=20, batch_size=1):\n",
    "    next_token_params = NextTokenChooserParameters(\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        typical_p=1,\n",
    "        seed=9248039014309552135,\n",
    "        repetition_penalty=1\n",
    "    )\n",
    "\n",
    "    stopping_params = StoppingCriteriaParameters(\n",
    "        max_new_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    requests = [Request(\n",
    "        id=i, \n",
    "        inputs=\"What is Deep Learning?\",\n",
    "        truncate=1024,\n",
    "        parameters=next_token_params,\n",
    "        stopping_parameters=stopping_params\n",
    "    ) for i in range(batch_size)]\n",
    "\n",
    "    return Batch(\n",
    "        id=0,\n",
    "        requests=requests,\n",
    "        size=batch_size,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "def main(model_id, iterations=3, num_tokens=100, batch_size=1):\n",
    "    model = get_model(\n",
    "        model_id=model_id,\n",
    "        revision=None,\n",
    "        dtype=\"float16\",\n",
    "        quantize=None,\n",
    "        sharded=True,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    batch = model.batch_type.from_pb(\n",
    "        create_batch(max_tokens=num_tokens, batch_size=batch_size), model.tokenizer, model.dtype, model.device\n",
    "    )\n",
    "    \n",
    "    model.warmup(batch)\n",
    "\n",
    "    tokens = []\n",
    "    with torch.no_grad():\n",
    "        start = time.perf_counter()\n",
    "        for _ in tqdm.tqdm(range(iterations)):\n",
    "            for _ in range(num_tokens):\n",
    "                generations, next_batch = model.generate_token(batch)\n",
    "                tokens.append(generations[15].token_text)\n",
    "    \n",
    "        torch.cuda.synchronize()\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        print(tokens)\n",
    "        print(f\"Time = {end - start: 0.2f}\")\n",
    "        print(f\"Tokens = {num_tokens * batch_size * iterations}\")\n",
    "        print(f\"Tokens/sec = {num_tokens * batch_size * iterations / (end-start): 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "473260dd-f107-4a7d-906f-25706c62e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['batch_id', 'requests', 'requests_idx_mapping', 'input_ids', 'attention_mask', 'position_ids', 'past_key_values', 'all_input_ids', 'input_lengths', 'prefix_offsets', 'read_offsets', 'next_token_choosers', 'stopping_criterias', 'max_input_length', 'padding_right_offset', 'max_tokens', 'keys_head_dim_last'])\n"
     ]
    }
   ],
   "source": [
    "print(next_batch.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3590f607-1d46-4585-9c1d-420d31cdee05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLASH_ATTENTION = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Learning', ' is', ' a', ' new', ' type', ' of', ' machine', ' learning', ' that', ' is', ' used', ' to', ' solve', ' complex', ' problems', '.', ' It', ' is', ' a', ' type', ' of', ' machine', ' learning', ' that', ' uses', ' deep', ' neural', ' networks', ' to', ' learn', ' complex', ' mathematical', ' functions', '.', ' Deep', ' Learning', ' is', ' a', ' type', ' of', ' machine', ' learning', ' that', ' uses', ' deep', ' neural', ' networks', ' to', ' learn', ' complex', ' mathematical', ' functions', '.', ' Deep', ' Learning', ' is', ' a', ' type', ' of', ' machine', ' learning', ' that', ' uses', ' deep', ' neural', ' networks', ' to', ' learn', ' complex', ' mathematical', ' functions', '.', ' Deep', ' Learning', ' is', ' a', ' type', ' of', ' machine', ' learning', ' that', ' uses', ' deep', ' neural', ' networks', ' to', ' learn', ' complex', ' mathematical', ' functions', '.', ' Deep', ' Learning', ' is', ' a', ' type', ' of', ' machine', ' learning', ' that']\n",
      "Time =  1.73\n",
      "Tokens = 1600\n",
      "Tokens/sec =  925.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main(model_id, iterations=1, num_tokens=num_tokens, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8dda6c74-1336-43ba-873d-659633c8fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = create_batch()\n",
    "batch = model.batch_type.from_pb(\n",
    "        create_batch(max_tokens=num_tokens), model.tokenizer, model.dtype, model.device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b43e33a-a1ef-42f9-817d-829c9a8566c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<text_generation_server.models.bloom.BLOOMSharded at 0x7fafe38f67c0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be41c209-f396-4617-a4b6-569e47ba6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations, next_batch = model.generate_token(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff552447-a069-4c7c-add6-825ff312fd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a6870-d700-452e-a850-ea71f0710faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
